{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import mnist\n",
    "\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from skimage.util import view_as_windows\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same padding\n",
    "def to_windows(img,window_shape,step_shape,dims=None):\n",
    "    pad = []\n",
    "    if dims is None : dims = img.ndim\n",
    "    # for all channels (multi dim support)\n",
    "    for i in range(img.ndim):\n",
    "        if i < dims:\n",
    "            n = img.shape[i]\n",
    "            s = step_shape[i]\n",
    "            f = window_shape[i]\n",
    "            p = int((f + (n - 1)*s - n)/2) # compute nencessary padding for same padding\n",
    "        else:\n",
    "            p = 0\n",
    "        pad.append((p,p))\n",
    "    # pad has necessary padding for each axis at this point\n",
    "    img_padded = np.pad(img, tuple(pad), 'constant', constant_values=(0)) # apply paddings\n",
    "    output = view_as_windows(img_padded,window_shape,step_shape) # slide windows across image and save contents (padded image)\n",
    "    output = output.reshape( -1, np.prod( window_shape ) ) # 28*28*5*5 -> 784*25\n",
    "    return output\n",
    "\n",
    "# heviside of matrix\n",
    "def H(x):\n",
    "    y = np.zeros(x.shape) \n",
    "    y[x>0] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine convolution and Membership function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outro paper... nao usar (maybe)\n",
    "def regular_convolution(x,K):\n",
    "    kernel_shape = K.shape\n",
    "    step_shape = tuple(np.ones(len(kernel_shape)).astype(int))\n",
    "    data = to_windows(x,kernel_shape,step_shape)\n",
    "    W = K.reshape(1,-1)\n",
    "    logits = data @ W.T\n",
    "    return logits.reshape(x.shape)\n",
    "\n",
    "# esta foi usada no paper (quase de certeza)\n",
    "def cosine_convolution(x,K,wta=True):    # TODO: falta o W como argumnto\n",
    "    k = K.shape[0]\n",
    "    kernel_shape = K.shape[1:]\n",
    "    step_shape = tuple(np.ones(len(kernel_shape)).astype(int))\n",
    "    data = to_windows(x,kernel_shape,step_shape)\n",
    "    norms = np.linalg.norm(data,axis=1,keepdims=True)\n",
    "    out = (norms<=0)[:,0]\n",
    "    norms[out] = 1\n",
    "    data = data / norms\n",
    "    W = K.reshape(k,-1)\n",
    "    norms = np.linalg.norm(W,axis=1,keepdims=True)\n",
    "    W = W / norms\n",
    "    d = ((data @ W.T) + 1)/2 # @ is matrix mul TODO: ver o que Ã© este +1 /2\n",
    "    if wta:\n",
    "        t = d.max(axis=1,keepdims=True) # para cada window da imagem selecionar a mais similar\n",
    "        t[np.linalg.norm(data,axis=1)<=0] = np.inf\n",
    "        o = np.zeros(d.shape)\n",
    "        o[(t-d)<=0] = d[(t-d)<=0]\n",
    "        o = o.reshape(x.shape + (k,)) # imagem 28*28*K(num features)\n",
    "        return o\n",
    "    return d.reshape(x.shape + (k,)) \n",
    "\n",
    "# tb posso usar esta\n",
    "def euclid_convolution(x,km,wta=True):  #km== objecto que contem o resultado do k-means \n",
    "    k = km.cluster_centers_.shape[0] # resultado dos centroids\n",
    "    kernel_shape = int(np.sqrt(km.cluster_centers_.shape[1]))\n",
    "    kernel_shape = (kernel_shape,kernel_shape)\n",
    "    step_shape = tuple(np.ones(len(kernel_shape)).astype(int))\n",
    "    data = to_windows(x,kernel_shape,step_shape)\n",
    "    d = 1/km.transform(data) # transform calcula distancia aos centroids\n",
    "    if wta:\n",
    "        t = d.max(axis=1,keepdims=True)\n",
    "        t[np.linalg.norm(data,axis=1)<=0] = np.inf\n",
    "        o = np.zeros(d.shape)\n",
    "        o[(t-d)<=0] = d[(t-d)<=0]\n",
    "        o = o.reshape(x.shape + (k,))\n",
    "        return o\n",
    "    return d.reshape(x.shape + (k,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mu_ret(img,K,T_ret,wta=True): # recebe imagem, k(n features) e threshold e calcula a convolution e \n",
    "    z = cosine_convolution(img,K,wta=wta)\n",
    "    #z = euclid_convolution(img,K,wta=wta)\n",
    "    a = H(z - np.quantile(z[z>0],q=T_ret))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set enumeration and Geometric transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enum_set(a):\n",
    "    n_H, n_W, n_K = a.shape\n",
    "    k = np.linspace(1, n_K, n_K)\n",
    "    h = np.flip(np.linspace(0, n_H-1, n_H))\n",
    "    w = np.linspace(0, n_W-1, n_W)\n",
    "    W, H, K = np.meshgrid(w, h, k)\n",
    "    k = K[a!=0]\n",
    "    h = H[a!=0]\n",
    "    w = W[a!=0]\n",
    "    ret_set = np.zeros((k.shape[0],3))\n",
    "    ret_set[:,0] = ((w/(n_W-1))*2)-1\n",
    "    ret_set[:,1] = ((h/(n_H-1))*2)-1\n",
    "    ret_set[:,2] = k\n",
    "    return ret_set # 3 colunas: pos em x pos em y, feature q ganhou\n",
    "\n",
    "def translation(features,C_x,C_y):\n",
    "    M = np.eye(3)\n",
    "    M[0:-1,-1] = (C_x,C_y)\n",
    "    pos = np.copy(features)\n",
    "    pos[:,-1] = 1\n",
    "    pos = np.dot(M,pos.T).T\n",
    "    pos[:,-1] = features[:,-1]\n",
    "    return pos\n",
    "\n",
    "def scale(features,rad):\n",
    "    pos = np.copy(features)\n",
    "    M = np.diag([1./rad,1./rad])\n",
    "    pos[:,0:2] = np.dot(M,pos[:,0:2].T).T\n",
    "    return pos\n",
    "    \n",
    "def rotation(features,theta): # nao usado no paper\n",
    "    pos = np.copy(features)\n",
    "    M = np.array([[np.cos(theta),-np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n",
    "    pos[:,0:2] = np.dot(M,pos[:,0:2].T).T\n",
    "    return pos\n",
    "\n",
    "def polar_transform(x):\n",
    "    cx,cy = np.mean(x[:,0:2],axis=0)\n",
    "    w = x[:,0]\n",
    "    h = x[:,1]\n",
    "    rad = np.max(np.sqrt((w - cx)**2 + (h - cy)**2))\n",
    "    pol = scale(translation(x,-cx,-cy),rad)\n",
    "    return pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_encoding(x,Q,k):\n",
    "    pol = np.zeros(x.shape)\n",
    "    pol[:,0] = x[:,1]\n",
    "    pol[:,1] = x[:,0]\n",
    "    pol[:,2] = x[:,2]\n",
    "    h = np.histogramdd(pol, bins=(Q,Q,k), range=[(-1,1),(-1,1),(1,k)])[0] # conta para cada posi da grelha qnts pontos estao la dentro\n",
    "    h = np.flip(h,axis=0) # for visualization purposes y axist pointing down\n",
    "    h[h>0] = 1 # transofrma histograma em binary [0,1,2] -> [0,1,1]\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionary learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "D conjunto de treino\n",
    "K num features\n",
    "patch_size: tamnaho da window \n",
    "background :  minimum windows norm\n",
    " \"\"\"\n",
    "def learn_dictionary(D,k,patch_size,rng,n_epochs,background=0.8,kmeans=None):\n",
    "    print('Learning the dictionary... ')\n",
    "    if kmeans is None:\n",
    "        kmeans = MiniBatchKMeans(n_clusters=k, random_state=rng, verbose=True)\n",
    "    buffer = []\n",
    "    t0 = time.time()\n",
    "    index = 0\n",
    "    for _ in range(n_epochs):\n",
    "        for img in D:\n",
    "            data = to_windows(img,patch_size,tuple(np.ones(len(patch_size)).astype(int)))\n",
    "            norms = np.linalg.norm(data,axis=1,keepdims=True)\n",
    "            keep = norms>background\n",
    "            keep = keep[:,0]\n",
    "            data = data[keep,:]\n",
    "            #norms = norms[keep,:]\n",
    "            #data = data / norms\n",
    "            data = np.reshape(data, (len(data), -1))\n",
    "            buffer.append(data)\n",
    "            index += 1\n",
    "            if index % 10 == 0:\n",
    "                data = np.concatenate(buffer, axis=0)\n",
    "                #data -= np.mean(data, axis=0)\n",
    "                #data /= np.std(data, axis=0)\n",
    "                kmeans.partial_fit(data)\n",
    "                buffer = []\n",
    "            if index % 100 == 0:\n",
    "                print('Partial fit of %4i out of %i'% (index, n_epochs * len(D)))\n",
    "    dt = time.time() - t0\n",
    "    print('done in %.2fs.' % dt)\n",
    "    return kmeans.cluster_centers_.reshape((-1,) + patch_size),kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict(W,patch_size):\n",
    "    plt.figure(figsize=(4.2, 4))\n",
    "    for i, patch in enumerate(W):\n",
    "        plt.subplot(9, 9, i + 1)\n",
    "        plt.imshow(patch.reshape(patch_size), cmap=plt.cm.gray,\n",
    "                   interpolation='nearest')\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "    \n",
    "    plt.subplots_adjust(0.08, 0.02, 0.92, 0.85, 0.08, 0.23)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = mnist.train_images()/255.\n",
    "y_D = mnist.train_labels()\n",
    "T = mnist.test_images()/255.\n",
    "y_T = mnist.test_labels()\n",
    "print(\"Shape: \" + str(D.shape))\n",
    "print(\"Example: \")\n",
    "plt.imshow(D[np.random.permutation(D.shape[0])[0]],cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0) Baseline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "rng = np.random.RandomState(0)\n",
    "k = 30 # aumaentar isto para ter mais sparsity\n",
    "kernel_shape = (5,5)\n",
    "T_what = 0.6 # subir isto para ficar mais sparse\n",
    "Q = 18 # aumentar a grelha para mais sparsity\n",
    "wta = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "K,km = learn_dictionary(D,k,kernel_shape,rng,n_epochs,background=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict(K,kernel_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = np.zeros((D.shape[0],k*Q**2))\n",
    "for i in range(D.shape[0]):\n",
    "    if i % 10000 == 0:\n",
    "        print(i)\n",
    "    img = D[i]\n",
    "    a = mu_ret(img,km,T_what,wta=True)\n",
    "    s = enum_set(a)\n",
    "    p = polar_transform(s)\n",
    "    e = grid_encoding(p,Q,K.shape[0])\n",
    "    X_trn[i] = e.flatten()\n",
    "X_trn = csr_matrix(X_trn) # guardar como matrix esparsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst = np.zeros((T.shape[0],k*Q**2))\n",
    "for i in range(T.shape[0]):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    img = T[i]\n",
    "    a = mu_ret(img,km,T_what,wta=True)\n",
    "    s = enum_set(a)\n",
    "    p = polar_transform(s)\n",
    "    e = grid_encoding(p,Q,K.shape[0])\n",
    "    X_tst[i,:] = e.flatten()\n",
    "X_tst = csr_matrix(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
