\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath}
\usepackage{float}
\usepackage[super]{nth}

\title{Iterative Abstract creation}
\author{R. Simas }

\begin{document}

\maketitle

\section{Version 1}

\begin{abstract}
%The problem
Drawing from memory the face of a friend you haven't seen in years is a harsh task. However, if you happen to cross paths, you would easily recognize each other.
The biological memory is equipped with an impressive compression algorithm that is able to store the essential, and then infer the details to match the perception.
Associative Memories are a family of biologically inspired Artificial Neural Networks that aim to mimic these mechanisms of biological memories.
This family of models has been studied extensively, and it is known that they work better if their inputs are informative compressions, rather than raw data.
%What will I do
The starting point for my project is a mechanism developed by my supervisors that transforms raw images into informative binary compressions.
While these informative compressions are very well-suited for associative memories, they lack interpretability since they have moved the patterns from a comprehensible image space, into an abstract latent-feature space.
In my project, I will explore the opposite direction. That is mechanisms that take the abstract compressions, and transform them into concrete images. Essentially, drawing from memory. 
%How I will do it
To do so, I will explore three tools: Autoencoders, Variational Autoencoders, and Generative Adversarial Networks. What these Machine Learning tools all have in common is the ability to learn both the compression and decompression of images simultaneously. If I manage to manipulate these models into learning a compression mechanism that is suitable for associative memories, such as my starting point, I will also get the decompression mechanism for free.
%Datasets
In practice, I will utilize image datasets such as the popular MNIST database. For most of the experiments I don't foresee the need for labeled data, so unsupervised learning datasets such as STL-10 might also be a viable option.
%Expected results
The results will be evaluated both quantitatively (e.g., comparing reconstruction with the closest training example, clustering, etc.), and qualitatively (e.g., visual inspection). Highly realistic reconstructions are not necessarily the goal. An exciting result would be to obtain simplified/imperfect versions of patterns, like drawings from memory.

\end{abstract}
\newpage
\section{Version 2}

\begin{abstract}
%Intro
Drawing from memory the face of a friend you \textbf{have not} seen in years is a \textbf{difficult} task. However, if you happen to cross paths, you would easily recognize each other.
The biological memory is equipped with an impressive compression algorithm that is able to store the essential, and then infer the details to match the perception.
Associative Memories are a family of biologically inspired Artificial Neural Networks that aim to mimic these mechanisms of \textbf{their biological counterpart}.
%Sparse coding problem
This family of models has been studied extensively, and it is known that they work better if their inputs \textbf{are sparse and distributed vectors, rather than raw data. For this reason, Associative Memories require sparse encoding prescriptions that compress raw data into informative vectors.}
%What will I do
\textbf{The starting point for my project is one such prescription. It takes inspiration from the visual cortex to transform visual patterns into informative compressions $C$.}
While $C$ are very well-suited for associative memories, they lack interpretability since they have moved the patterns from a comprehensible image space, into an abstract latent-feature space.
In my project, I will explore the opposite direction\textbf{, that is,} mechanisms that take the abstract compressions $C$, and transform them into concrete images. Essentially, drawing from memory. 
%How I will do it
\textbf{To this end}, I will use Autoencoders and Variational Autoencoders. These two machine learning models have the ability to learn both the compression and decompression of images simultaneously. \textbf{I hypothesize that if these models are guided into learning a compression mechanism that is suitable for associative memories, then the decompression module can be used to transform $C$ back into images.
%GANs
Additionally I will experiment with Generative Adversarial Networks. This class of models allows for the direct generation of novel realistic patterns. The generation process requires a seed, which is usually random noise. I hypothesize that $C$ could be used as the seed instead.}
%Datasets
In practice, I will utilize image datasets such as the popular MNIST database. For most of the experiments I \textbf{do not} foresee the need for labeled data, so unsupervised learning datasets such as STL-10 might also be a viable option.
%Expected results
The results will be evaluated both quantitatively (e.g., comparing reconstruction with the closest training example, clustering, etc.), and qualitatively (e.g., visual inspection). Highly realistic reconstructions are not necessarily the goal. An exciting result would be to obtain simplified/imperfect versions of patterns, like drawings from memory.

\end{abstract}

\newpage
\section{Version 3}

\begin{abstract}
%The problem
Drawing from memory the face of a friend you have not seen in years is a difficult task. However, if you happen to cross paths, you would easily recognize each other.
The biological memory is equipped with an impressive compression algorithm that is able to store the essential, and then infer the details to match perception.
Associative Memories are a family of biologically inspired Artificial Neural Networks that aim to mimic these mechanisms of their biological counterpart.
Their usage in practical applications requires prescriptions that transform raw data into sparse compressions.
%What will I do
The starting point for my project is one such prescription, which transforms visual patterns into ``What-Where" sparse feature maps.
While these What-Where codes are very well-suited for associative memories, they lack interpretability since they have moved the patterns from a comprehensible image space, into an abstract latent-feature space.
In my project, I will explore the opposite direction, that is, mechanisms that take the What-Where codes, and transform them into concrete images. Essentially, drawing from memory. 
%How I will do it
To do so, I will use Autoencoders and its several variants (e.g., sparse, variational, etc.). This family of Machine Learning tools has the ability to learn both the encoding and decoding directions simultaneously. I hypothesize that if these models are built as prescriptions for associative memories, then the decoding module could be used to fullfill my research goal.
%Expected results
The results will be evaluated both quantitatively (e.g., comparing reconstruction with the closest training example, clustering, etc.), and qualitatively (e.g., visual inspection). Highly realistic reconstructions are not necessarily the goal. An exciting result would be to obtain simplified/imperfect versions of patterns, like drawings from memory.

\end{abstract}

\end{document}

\section{Conclusion V1}

% Goal of the document
This document is the final report for my Master Thesis' Introduction course.
%Background
The ultimate goal of Artificial Intelligence (AI) is to build computer programs that display human-like intelligence. Since the human brain is the most intelligent system that we know of, there is great value in building \textit{biologically inspired} AI models that attempt to imitate the mechanisms of biological systems.
Associative Memories (AMs) are \textit{biologically inspired} models that store associations between pairs of vectors. Their performance skyrockets if the patterns they store are sparse codes. The main problem with AMs which has prevented them from being used in practice, is the fact that real world data is not sparse but dense. As a result, recent research on AM has focused on developing prescriptions that transform raw visual patterns into sparse codes.
%The starting point for the thesis
My supervisors at T\'ecnico have recently developed one such prescription for visual patterns \cite{sa2020storing}, which I refer to as What-Where (WW) codes throughout this document. These WW codes are essentially feature detectors that heavily compress the original patterns. While these compressions are very suitable for AMs, they lack interpretability since they moved the patterns from the visual space into an abstract feature space. My reseach goal is to find a mechanism that 
% The tools I will use

We plan to test the quality of the reconstruction on the MNIST dataset of hand written digits. For most of the experiments I donâ€™t foresee the need for labeled data, so unsupervised learning datasets such as STL-10 might also be a viable option if addicional datasets are required.
The quality of reconstruction can be analysed with GANs. If the discriminator mod
% The results i expect (hypothesis)
Lastly, we present a tentative schedule that will be used to guide the work I will do in the upcoming semester.